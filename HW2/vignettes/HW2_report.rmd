---
# Document metadata information:
title: "Homework 2 Report"
subtitle: Classification of liver malfunction severity (Logistic Regression)
author: "Ian Effendi"
email: iae2784@rit.edu
date: September 14, 2021
# Output formats:
output:
  # Output as a previewable HTML Notebook.
  html_notebook:
    theme: lumen
    highlight: tango
    df_print: paged
    toc: true
    toc_depth: 3
    toc_float: true
  # Output as an rmarkdown::pdf_document()
  pdf_document:
    keep_tex: true
    highlight: tango
    fig_caption: true
    df_print: kable
    toc: true
    toc_depth: 3
# Package vignette options:
vignette: >
  %\VignetteIndexEntry{Homework 2 Report}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
# pandoc -> pdfLaTeX rendering options:
fontsize: 11pt
geometry:
  - margin=1in
  - heightrounded
documentclass: scrartcl
papersize: a4
urlcolor: violet
toccolor: blue
# Custom knit function.
knit: (function(inputFile, encoding){
  rmarkdown::render(inputFile, encoding = encoding, 
  output_dir = "inst/doc", 
  output_format="all") })
---

```{r setup, include=FALSE}
# Setup the document settings.
knitr::opts_knit$set(
  # Set the working directory to the project root.
  root.dir = here::here()
)

# Setup the chunk options.
knitr::opts_chunk$set(
  cache = TRUE,
  collapse = TRUE,
  echo = TRUE,
  warning = TRUE,
  message = TRUE,
  comment = "#",
  R.options = list(width = 60)
)

# Read chunks from external scripts.
knitr::read_chunk(here::here('data-raw/liver_data.R'))
knitr::read_chunk(here::here('data-raw/severity_map.R'))
knitr::read_chunk(here::here('R/utils-confmat.R'))
knitr::read_chunk(here::here('R/utils-lec3.R'))
```

## Certification

> I certify that I indeed finished reading Ch. 3 from *An Introduction to Statistical Learning*, by James Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani.

## Overview

<!-- This section provides an overview of the report. -->

In this assignment we will:

- Extract, load, and transform (*ELT*) the `Liver.txt` dataset.
- Perform exploratory data analysis (*EDA*) on the dataset.
- Fit and analyze a logistic regression model on the dataset.
- Perform multiple cross-validation tasks at different k-fold values ($k = 3,\, k = 10$).

This report was generated as a vignette in a formal [R Package](https://r-pkgs.org/intro.html) structured specifically for data analysis, with the following package requirements:

<!-- This chunk loads the packages and stops output -->
```{r load-packages, echo=FALSE, include=FALSE}
library(reshape2)
library(dplyr)
library(forcats)
library(ggplot2)
library(corrplot)
```

<!-- This chunk just displays the packages without evaluation -->
```{r show-packages, ref.label="load-packages", collapse=TRUE, eval=FALSE}
```

## ELT {.tabset}

The `Liver.txt` file contains a header-less set of comma-separated fields, with one record per newline.

### Extraction

We begin by getting the filepath for `Liver.txt`, which is stored in the package's `inst/extdata` folder:

```{r find-liver-txt}
```

Next, we prepare the column names:

```{r prep-liver-names}
```

Then, we prepare the column types:

```{r prep-liver-types}
```

Now we extract and save the `Liver.txt` file to place in our `data/` folder as a `liver_data.rda` file. This also allows us to refer to the data with `liver_data`.

```{r read-liver-txt}
```

```{r save-liver-txt, results='hide'}
```

### Loading

The `*.rda` data files are saved within the `data/` folder. When the package is installed (eg., `devtools::load_all("RIT.STAT745.HW2")` from the project directory), this attaches our `liver_data` tibble to the working environment:

```{r preview-liver-txt}
library(RIT.STAT745.HW2)

str(liver_data)
```
### Transformation

Transformation of the dataset is minimal. In our case we want to encode our response variable `severity` to properly mention our *positive* and *negative* class labels. We can trivally declare a lookup table that provides us with an adequate data dictionary:

```{r make-severity-map, include=FALSE, results='hide'}
```

```{r preview-severity-map}
severity_map
```

```{r encode-severity}
liver <- liver_data %>%
  mutate(severity = fct_recode(severity,
    "0" = "2",
    "1" = "1"
  )) %>%
  mutate(severity = fct_rev(severity))

print(paste(c("Levels in `liver$severity`: ", levels(liver$severity)), collapse = " "))
```

<!-- PAGE BREAK -->
\newpage

## EDA {.tabset}

### Explore

```{r explore-dimensions}
# Structure of the dataframe.
dim(liver) # 345 observations and 3 variables.
```
```{r explore-structure}
# X1 through X5 are blood test results.
# X6 is no. of alcoholic beverages drunk.
# X7 is severity response, encoded as "Group 1" = 1 and "Group 2" = 0
str(liver)
```

### Analyze

```{r analyze-tests}
# Summarize the blood test predictors.
summary(liver[,1:5]) # No units were provided with dataset.
```

```{r analyze-drinks}
# Summarize the alcoholic beverage predictor.
summary(liver[,6]) 
# Median: 3 drinks, Mean: 3.5 drinks, skewed by Max: 20 drinks.
```

```{r analyze-severity}
# Summarize the severity.
summary(liver[,7])
# num(Group 2) > num(Group 1)
```

```{r plot-drinks-severity}
# Boxplot shows smaller median, wider spread in severe cases.
# Drinks may not be a strong predictor of liver malfunction.
ggplot(data = liver, mapping = aes(x = severity, y = drinks)) +
  geom_boxplot()
```
```{r plot-collinearity}
# blood.3 and blood.4 demonstrate multicollinearity.
pairs(liver %>% select(-severity))
```

<!-- PAGE BREAK -->
\newpage

## Classification {.tabset}

For this classification problem, we want to predict whether or not a patient's liver malfunction will be severe, given the predictors available in the dataset.

### Theory

The probability of a test observation having the positive class label outcome ("Group 1") is described by $p$ as such:

$$
p = Pr(Y = 1)
$$
Likewise, the probability of a test observation having the negative class label outcome ("Group 2") is described by $q$ as such:

$$
q = 1 - p = Pr(Y = 0)
$$
$severity$ can only take one of two values: $0$ or $1$. We denote $p = Pr(severity = 1)$ and we will fit a logistic regression model:

$$
ln[\frac{p}{(1-p)}] = \beta_0 + \beta_1(blood.1) + \cdots + \beta_5(blood.5) + \beta_6(drinks)
$$

We will predict $severity = 1$ if $p >= \pi_0$ and as $0$ otherwise. $\pi_0$ represents some arbitrary threshold probability we can select, but we'll begin with $\pi_0 = 0.5$.

### Model Fitting

We can fit a logistic regression model with Group 1 as the positive class as follows:

```{r fit-model}
liver.fit <- glm(
  severity ~ .,
  # Equivalent to:  severity ~ blood.1 + blood.2 + blood.3 + blood.4 + blood.5 + drinks, 
  data = liver,
  family = "binomial"
)
```

```{r analyze-fit, echo=1:1}
summary(liver.fit)
```
The fitted model summary suggests `drinks` is not a significant predictor of severity outcomes, but `blood.1~blood.5` all appear to play an important effect on the response.

### Model Performance

```{r confusion-matrix, include=FALSE}
```


```{r make-crosstable, message=FALSE}
# See "R/utils-confmat.R" for helper function definitions.
# Find predictions and make misclassification table.
p.threshold = 0.5
liver.prediction <- (liver.fit$fitted >= p.threshold)
liver.truth <- map.where(liver$severity == "1")
Classif.table <- table(liver.prediction, liver.truth)
knitr::kable(Classif.table)
```

```{r error-rate-funcs, include=FALSE, cache=FALSE}
```


```{r calc-error, echo=1, results='hold'}
ERR <- round(Error.rate.f(Classif.table), digits = 4)
FNR <- round(sum(liver$severity == "1")/length(liver$severity), digits = 4)
print(paste(c(sprintf("Total error rate (p >= %s): %s", 
              p.threshold, 
              ERR), 
        sprintf("False negative error rate (p >= %s): %s", 
              p.threshold, 
              FNR)), sep="\n"))
```
```{r plot-errors, fig.width=8, fig.height=6}
liver.ERR.rates <- All.error.rates.f(
  Truth = (liver$severity == "1"),
  Pred = liver.fit$fitted
)
Plot.Error.f(lista = liver.ERR.rates, cex=1.4)
```

As shown by the plot, the total error rate is optimized when the threshold is $\approx 0.516$. The misclassification for the optimal case:

```{r optimal-case, message=FALSE}
p.threshold = 0.516
liver.prediction <- (liver.fit$fitted >= p.threshold)
liver.truth <- map.where(liver$severity == "1")
Classif.table <- table(liver.prediction, liver.truth)
knitr::kable(Classif.table)
```
## Cross-Valdiation {.tabset}

```{r cross-validation-funcs, include=FALSE}
# Get the CV.error for the data.
CV.error.f <- function(data, k=10, t1=0, t2=1, m=20, rounds=2) {
  
  # k-fold CV; uses m=100 thresholds from t1 to t2:
  P.Thresholds <- seq(from=t1, to=t2, length=m)
  
  # Initialize the cost array:
  Cost.arr <- array(0,c(m, rounds, k))
  
  # Perform cross-validation "Rounds" times.
  for (i in 1:rounds) {
    
    # Sample data with repetitions k-times.
    fold=sample(rep(1:k,length=nrow(data)))
    
    # Perform j out of k folds.
    for (j in 1:k) {
      # Get the current fold:
      cond <- (fold==j)
      train_data <- data[!cond,]
      test_data <- data[cond,]
      
      # Fit the logistic regression model:
      obj <- glm(severity ~ ., data = train_data, family = "binomial")
      
      # Get the predictions:
      data.pred.proba <- predict(obj, newdata = test_data, type = "response")
      
      # Get logical truth:
      data.truth <- (test_data$severity == "1")
      
      # For each threshold, calculate the cost.
      for (ind in 1:m) {
        
        # Get the predicted label.
        data.pred <- (data.pred.proba >= P.Thresholds[ind])
        
        # Get weighted average of false neg class + truth.
        fn.avg <- mean((data.pred == FALSE) & (data.truth == TRUE)) * 10
        fp.avg <- mean((data.pred == TRUE) & (data.truth == FALSE))
        
        # Calculate the cost.
        Cost.arr[ind, i, j] <- fn.avg + fp.avg
        
        # Cost.arr[ind,i,j] <- mean((prediction==F)&(Truth==T))*10 +
        #  mean((prediction==T)&(Truth==F)) # not using "table"
      }
    }
  }
  list(Cost=Cost.arr, Threshold=P.Thresholds)
}

Plot.CV.Cost.f <- function(lista=CV.error.list,from=0, to=1) {
  Threshold <- lista$Threshold
  cond <- ((Threshold>=from)&(Threshold<=to)) # range
  Threshold <- Threshold[cond]
  Cost.arr <- lista$Cost[cond,,]
  N <- prod(dim(Cost.arr)[2:3]) # Rounds*k
  cost <- apply(Cost.arr,1,mean)
  cost.se <- apply(Cost.arr,1,sd)/sqrt(N)
  low <- cost - 2*cost.se;   high <- cost + 2*cost.se
  mat <- cbind(cost,low,high)
  # now calculating the optimal threshold
  min.val <- min(cost)
  ind <- match(min.val, cost) # Threshold[ind] is the optimal threshold
  par(mar = c(4.5,4.5,0,1))
  matplot(Threshold,mat,type="l", xlab=paste("Threshold (optimal at ",
      round(Threshold[ind],3),")"), ylab="Cost of Misclassification",lty=c(1,2,2))
  abline(h=min.val, lty=2);
  abline(v=Threshold[ind], lty=2)
  list(min.Cost=min.val, min.Threshold=Threshold[ind]) # the optimal threshold in case we need it
}
```

```{r cross-validation-summary-funcs, include=FALSE}

# Calculate CV Misclassification table for a fixed threshold.
CV.table.f <- function(data, k = 10, rounds = 5, P.Threshold = 0.5) {
  # k-fold CV for the optimal threshold.
  Classif.table.arr <- array(0, c(2, 2, rounds, k))
  
  # For each round...
  for(i in 1:rounds) {
    # Sample data with repetitions k-times.
    fold=sample(rep(1:k,length=nrow(data)))
    
    # For each fold...
    for(j in 1:k) {
      
      # Get the current fold:
      cond <- (fold==j)
      train_data <- data[!cond,]
      test_data <- data[cond,]
      
      # Fit the logistic regression model:
      obj <- glm(severity ~ ., data = train_data, family = "binomial")
      
      # Get the predictions:
      data.pred.proba <- predict(obj, newdata = test_data, type = "response")
      
      # Get logical truth:
      data.truth <- (test_data$severity == "1")
      
      # Get the prediction label at optimal threshold.
      data.pred <- (data.pred.proba >= P.Threshold)
      
      # Form the classification table.
      Classif.table.arr[,,i,j] <- table(data.pred, data.truth)
    }
  }
  
  # Return the table.
  return(Classif.table.arr)
}

Summary.CV.table.f <- function(arr=CV.table.arr) {
  arr <- apply(arr, 1:3, sum) # Summarize the fold.
  N <- dim(arr)[3]
  table.mean <- apply(arr, 1:2, mean)
  table.se <- apply(arr, 1:2, sd) / sqrt(N)
  return(
    list(
      Mean=table.mean,
      StErr=table.se
    )
  )
}

```

We use the following settings for our CV runs:

```{r setup-cv}
k.folds = c(10,3)
t.limit = c(0.001, 1.0)
n.thresholds = 200
n.rounds = 100
```


### $k = 10$ -fold CV

Below is a 10-fold cross-validation, using 100 rounds:

```{r ten-fold-cv, echo=FALSE, results='asis'}
# Plot k = 10 fold, 100 rounds:
CV.error.list <- CV.error.f(liver, k = k.folds[1], t1 = t.limit[1], t2 = t.limit[2], m = n.thresholds, rounds = n.rounds)
results <- Plot.CV.Cost.f(CV.error.list)
knitr::kable(as.data.frame(results), 
      col.names = c(
        min.Cost = "Minimum Cost", 
        min.Threshold = "Minimum Threshold"))
```

```{r summary-ten-fold, echo=FALSE, results='hold'}
CV.ten.table.arr <- CV.table.f(liver, k = k.folds[1], 
                               rounds = n.rounds, 
                               P.Threshold = results$min.Threshold)
print(Summary.CV.table.f(arr=CV.ten.table.arr))
```



### $k = 3$ -fold CV

Below is a 3-fold cross-validation, using 100 rounds:

```{r three-fold-cv, echo=FALSE, results='asis'}
# Plot k = 3 fold, 100 rounds:
CV.error.list2 <- CV.error.f(liver, k = k.folds[2], t1 = t.limit[1], t2 = t.limit[2], m = n.thresholds, rounds = n.rounds)
results2 <- Plot.CV.Cost.f(CV.error.list2)
knitr::kable(as.data.frame(results2), col.names = c(min.Cost = "Minimum Cost", min.Threshold = "Minimum Threshold"))
```

```{r summary-three-fold, echo=FALSE, results='hold'}
CV.three.table.arr <- CV.table.f(liver, k = k.folds[2], 
                               rounds = n.rounds, 
                               P.Threshold = results2$min.Threshold)
print(Summary.CV.table.f(arr=CV.three.table.arr))
```
<!-- PAGE BREAK -->
\newpage

## Session Information

*This document was generated from an [R Markdown](http://rmarkdown.rstudio.com) Notebook (See the `vignettes/HW2_report.Rmd` in the package's sub-directory). The setup chunk for this document sets the root directory to the project root directory using the `rprojroot` package; all file paths are relative to the project root.*

```{r session-info, echo=FALSE, results='markup', cache=FALSE}
sessionInfo()
```
